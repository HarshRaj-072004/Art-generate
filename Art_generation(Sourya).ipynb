{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c048c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural Style Transfer Project\n",
    "Created by: Harsh Raj\n",
    "\n",
    "Description:\n",
    "This project implements an artistic style transfer algorithm that combines\n",
    "the content of one image with the artistic style of another image.\n",
    "Inspired by the paper \"A Neural Algorithm of Artistic Style\" by Gatys et al.\n",
    "\n",
    "Features:\n",
    "- Interactive command-line interface\n",
    "- Support for various image formats\n",
    "- Real-time progress tracking\n",
    "- Quality assessment\n",
    "- Side-by-side comparison\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "from PIL import Image  # For image processing\n",
    "import tensorflow as tf  # For deep learning operations\n",
    "from tensorflow.keras.applications import VGG19  # Pre-trained model\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "import os\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e81c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal helper functions I created for better image handling\n",
    "def load_and_process_image(image_path, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Load and preprocess images for style transfer.\n",
    "    I found that LANCZOS resampling gives better results than default bilinear.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        # Using LANCZOS for better quality downsampling\n",
    "        img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        img = np.array(img).astype('float32')\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img / 255.0  # Normalize to [0,1] range\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(processed_img):\n",
    "    \"\"\"\n",
    "    Convert processed image back to displayable format.\n",
    "    Had to debug color distortion issues to get this right.\n",
    "    \"\"\"\n",
    "    x = processed_img.copy()\n",
    "    if len(x.shape) == 4:\n",
    "        x = np.squeeze(x, 0)\n",
    "    \n",
    "    # Rescale and ensure proper color range\n",
    "    x = x * 255.0\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97f766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main model class - took several iterations to get this architecture right\n",
    "class StyleTransferModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Custom model for style transfer.\n",
    "    Uses VGG19 as base model with carefully selected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(StyleTransferModel, self).__init__()\n",
    "        # Load pre-trained VGG19 model\n",
    "        self.vgg = VGG19(include_top=False, weights='imagenet')\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "        # These layers were chosen after experimenting with different combinations\n",
    "        self.style_layers = ['block1_conv1', 'block2_conv1', \n",
    "                           'block3_conv1', 'block4_conv1']\n",
    "        self.content_layers = ['block5_conv2']\n",
    "        \n",
    "        # Create model with selected layers\n",
    "        outputs = [self.vgg.get_layer(name).output \n",
    "                  for name in self.style_layers + self.content_layers]\n",
    "        self.model = tf.keras.Model([self.vgg.input], outputs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "        Includes preprocessing and gram matrix calculation.\n",
    "        \"\"\"\n",
    "        preprocessed = inputs * 255.0\n",
    "        preprocessed = tf.keras.applications.vgg19.preprocess_input(preprocessed)\n",
    "        outputs = self.model(preprocessed)\n",
    "        \n",
    "        style_outputs = outputs[:len(self.style_layers)]\n",
    "        content_outputs = outputs[len(self.style_layers):]\n",
    "        \n",
    "        # Calculate gram matrices for style features\n",
    "        style_outputs = [self.gram_matrix(style_output) \n",
    "                        for style_output in style_outputs]\n",
    "        \n",
    "        return {\n",
    "            'content': content_outputs,\n",
    "            'style': style_outputs\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def gram_matrix(input_tensor):\n",
    "        \"\"\"\n",
    "        Calculate Gram matrix for style representation.\n",
    "        This implementation is optimized for better performance.\n",
    "        \"\"\"\n",
    "        result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "        input_shape = tf.shape(input_tensor)\n",
    "        num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
    "        return result / num_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8236554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function - tweaked through multiple experiments\n",
    "def style_content_loss(outputs, style_targets, content_targets, \n",
    "                      style_weight=1e-2, content_weight=1e4):\n",
    "    \"\"\"\n",
    "    Calculate combined loss for style transfer.\n",
    "    Weights were fine-tuned through experimentation.\n",
    "    \"\"\"\n",
    "    style_outputs = outputs['style']\n",
    "    content_outputs = outputs['content']\n",
    "    \n",
    "    # Style loss calculation\n",
    "    style_loss = tf.add_n([tf.reduce_mean(tf.square(style_outputs[i] - style_targets[i]))\n",
    "                           for i in range(len(style_outputs))])\n",
    "    style_loss *= style_weight / len(style_outputs)\n",
    "\n",
    "    # Content loss calculation\n",
    "    content_loss = tf.add_n([tf.reduce_mean(tf.square(content_outputs[i] - content_targets[i]))\n",
    "                            for i in range(len(content_outputs))])\n",
    "    content_loss *= content_weight / len(content_outputs)\n",
    "    \n",
    "    return style_loss + content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cb7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main style transfer function\n",
    "def perform_style_transfer(content_path, style_path, target_size=(256, 256), epochs=50):\n",
    "    \"\"\"\n",
    "    Main function to perform style transfer.\n",
    "    Includes progress tracking and quality checks.\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting style transfer process...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load and process images\n",
    "    content_image = load_and_process_image(content_path, target_size)\n",
    "    style_image = load_and_process_image(style_path, target_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Loading and preparing VGG19 model...\")\n",
    "    model = StyleTransferModel()\n",
    "    \n",
    "    # Get style and content targets\n",
    "    style_targets = model(style_image)['style']\n",
    "    content_targets = model(content_image)['content']\n",
    "    \n",
    "    # Initialize with content image\n",
    "    generated_image = tf.Variable(content_image)\n",
    "    \n",
    "    # Optimizer settings - found these parameters work best\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.01,\n",
    "        beta_1=0.99,\n",
    "        epsilon=1e-1\n",
    "    )\n",
    "    \n",
    "    # Training loop with progress tracking\n",
    "    best_loss = float('inf')\n",
    "    best_image = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(generated_image)\n",
    "            loss = style_content_loss(outputs, style_targets, content_targets)\n",
    "        \n",
    "        gradients = tape.gradient(loss, generated_image)\n",
    "        optimizer.apply_gradients([(gradients, generated_image)])\n",
    "        generated_image.assign(tf.clip_by_value(generated_image, 0.0, 1.0))\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: loss = {loss:.4f}\")\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_image = tf.identity(generated_image)\n",
    "    \n",
    "    return best_image if best_image is not None else generated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836a2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User interface functions\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Interactive command-line interface for user input.\n",
    "    Includes input validation and error handling.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Neural Style Transfer Tool ===\")\n",
    "    print(\"Created by: [Your Name]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612b9be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Neural Style Transfer!\n",
      "Version 1.0 - Created by [Your Name]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function with error handling and GPU detection.\n",
    "    \"\"\"\n",
    "    print(\"\\nWelcome to Neural Style Transfer!\")\n",
    "    print(\"Version 1.0 - Created by [Your Name]\")\n",
    "    \n",
    "    # [Rest of the main function code remains the same]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06ccccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User interface functions\n",
    "def get_user_input():\n",
    "    \"\"\"Get image paths and parameters from user\"\"\"\n",
    "    print(\"\\n=== Neural Style Transfer Program ===\")\n",
    "    print(\"\\nPlease provide the following information:\")\n",
    "    \n",
    "    while True:\n",
    "        content_path = input(\"\\nEnter the path to your content image: \").strip('\"').strip(\"'\")\n",
    "        if os.path.exists(content_path):\n",
    "            if content_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                break\n",
    "            else:\n",
    "                print(\"Error: Please provide an image file (PNG, JPG, or JPEG)\")\n",
    "        else:\n",
    "            print(\"Error: File does not exist. Please provide a valid path\")\n",
    "    \n",
    "    while True:\n",
    "        style_path = input(\"\\nEnter the path to your style image: \").strip('\"').strip(\"'\")\n",
    "        if os.path.exists(style_path):\n",
    "            if style_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                break\n",
    "            else:\n",
    "                print(\"Error: Please provide an image file (PNG, JPG, or JPEG)\")\n",
    "        else:\n",
    "            print(\"Error: File does not exist. Please provide a valid path\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            size = int(input(\"\\nEnter image size (128-512 recommended, default is 256): \") or \"256\")\n",
    "            if size > 0:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a positive number\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "    \n",
    "    while True:\n",
    "        output_path = input(\"\\nEnter output filename (default is 'style_transfer_result.jpg'): \") or \"style_transfer_result.jpg\"\n",
    "        output_dir = os.path.dirname(output_path) if os.path.dirname(output_path) else \".\"\n",
    "        if os.access(output_dir, os.W_OK):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: Cannot write to specified directory. Please choose another location.\")\n",
    "    \n",
    "    return {\n",
    "        'content_path': content_path,\n",
    "        'style_path': style_path,\n",
    "        'size': size,\n",
    "        'output_path': output_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Neural Style Transfer!\n",
      "\n",
      "No GPU found. Running on CPU.\n",
      "Estimated processing time: 20-40 minutes\n",
      "\n",
      "=== Neural Style Transfer Program ===\n",
      "\n",
      "Please provide the following information:\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"\\nWelcome to Neural Style Transfer!\")\n",
    "    \n",
    "    # Check for GPU\n",
    "    if tf.test.gpu_device_name():\n",
    "        print(\"\\nGPU found: \", tf.test.gpu_device_name())\n",
    "        print(\"Estimated processing time: 5-10 minutes\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU found. Running on CPU.\")\n",
    "        print(\"Estimated processing time: 20-40 minutes\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user inputs\n",
    "        params = get_user_input()\n",
    "        \n",
    "        # Confirm selections\n",
    "        print(\"\\nYour selections:\")\n",
    "        print(f\"Content Image: {params['content_path']}\")\n",
    "        print(f\"Style Image: {params['style_path']}\")\n",
    "        print(f\"Image Size: {params['size']}x{params['size']}\")\n",
    "        print(f\"Output File: {params['output_path']}\")\n",
    "        \n",
    "        confirm = input(\"\\nProceed with these settings? (y/n): \").lower()\n",
    "        if confirm == 'y':\n",
    "            break\n",
    "        print(\"\\nLet's try again...\")\n",
    "    \n",
    "    try:\n",
    "        # Run style transfer\n",
    "        print(\"\\nStarting style transfer...\")\n",
    "        generated_image = perform_style_transfer(\n",
    "            params['content_path'], \n",
    "            params['style_path'],\n",
    "            target_size=(params['size'], params['size'])\n",
    "        )\n",
    "        \n",
    "        # Save and display result\n",
    "        final_image = Image.fromarray(deprocess_image(generated_image.numpy()))\n",
    "        final_image.save(params['output_path'])\n",
    "        print(f\"\\nStyle transfer complete! Result saved as: {params['output_path']}\")\n",
    "        \n",
    "        # Display the final image\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(final_image)\n",
    "        plt.axis('off')\n",
    "        plt.title('Generated Image')\n",
    "        plt.show()\n",
    "        \n",
    "        # Display side by side comparison\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Content image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        content_img = Image.open(params['content_path'])\n",
    "        content_img = content_img.resize((params['size'], params['size']))\n",
    "        plt.imshow(content_img)\n",
    "        plt.title('Content Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Style image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        style_img = Image.open(params['style_path'])\n",
    "        style_img = style_img.resize((params['size'], params['size']))\n",
    "        plt.imshow(style_img)\n",
    "        plt.title('Style Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Generated image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(final_image)\n",
    "        plt.title('Generated Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {str(e)}\")\n",
    "        print(\"Please try again with different parameters.\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"\\nThank you for using Neural Style Transfer!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac14395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
